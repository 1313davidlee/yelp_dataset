{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "cal = datasets.fetch_california_housing()\n",
    "data = cal['data']\n",
    "targets = cal['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R^2 Scores [0.54866323 0.46820691 0.55078434 0.53698703 0.66051406]\n",
      "Linear Regression Mean R^2 Score 0.5530311140279233\n",
      "\n",
      "Boosting R^2 Scores [0.60253089 0.69877396 0.71802327 0.65021286 0.67975317]\n",
      "Boosting Scores Mean R^2 Score 0.6698588296892413\n"
     ]
    }
   ],
   "source": [
    "# 1a\n",
    "clf = LinearRegression()\n",
    "scores = cross_val_score(clf, data, targets, cv=5)\n",
    "print('Linear Regression R^2 Scores', scores)\n",
    "print('Linear Regression Mean R^2 Score', np.mean(scores))\n",
    "print()\n",
    "\n",
    "clf = ensemble.GradientBoostingRegressor()\n",
    "scores = cross_val_score(clf, data, targets, cv=5)\n",
    "print('Boosting R^2 Scores', scores)\n",
    "print('Boosting Scores Mean R^2 Score', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/David/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for parameter grid search:\n",
      "\n",
      "0.334 (+/-0.055) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.476 (+/-0.060) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.407 (+/-0.082) for {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50}\n",
      "0.561 (+/-0.098) for {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.644 (+/-0.082) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.680 (+/-0.051) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.645 (+/-0.108) for {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50}\n",
      "0.647 (+/-0.107) for {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# 1b\n",
    "tuned_parameters = [{'max_depth': [3, 10],\n",
    "                     'n_estimators': [50, 100],\n",
    "                     'learning_rate': [0.01, 0.1]}]\n",
    "clf = ensemble.GradientBoostingRegressor()\n",
    "clf = GridSearchCV(clf, tuned_parameters)\n",
    "clf.fit(data, targets)\n",
    "\n",
    "print(\"Scores for parameter grid search:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c) Briefly discuss the performance and summarize your findings.**\n",
    "\n",
    "When running linear regression and gradient boosting using 5-fold cross validation, we got the following R^2 Score results:\n",
    "\n",
    "    Linear Regression Mean Score = 0.5530311140279233\n",
    "    Boosting Scores Mean Score = 0.6698681752149087\n",
    "\n",
    "Overall the scores are not great. R^2 measures the goodness-of-fit of the model on the data. R^2 closer to 1 is better. The boosting score is significantly greater than the linear regressor which makes sense.\n",
    "\n",
    "\n",
    "For 1b) we tested all of the following possible permutations:\n",
    "\n",
    "    'max_depth': [3, 10],\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "    \n",
    "Our parameter grid search yielded interesting results. None of the parameter combinations were convincingly better than the default parameters. In fact, increasing the max_depth and decreasing the learning rate were very detrimental to the R^2 score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_targets = np.array([x>2 for x in targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/David/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/David/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/David/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/David/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/David/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy [0.80988133 0.79796512 0.77616279 0.74612403 0.82481221]\n",
      "Logistic Regression Mean Accuracy 0.7909890954886174\n",
      "\n",
      "Boosting Classifier Accuracy [0.79099055 0.75436047 0.80741279 0.75339147 0.82650836]\n",
      "Boosting Classifier Mean Accuracy 0.7865327285758221\n"
     ]
    }
   ],
   "source": [
    "# 2a\n",
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, data, new_targets, cv=5)\n",
    "print('Logistic Regression Accuracy', scores)\n",
    "print('Logistic Regression Mean Accuracy', np.mean(scores))\n",
    "print()\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, data, new_targets, cv=5)\n",
    "print('Boosting Classifier Accuracy', scores)\n",
    "print('Boosting Classifier Mean Accuracy', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/David/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 2b\n",
    "tuned_parameters = [{'max_depth': [3, 5],\n",
    "                     'n_estimators': [100, 200],\n",
    "                     'learning_rate': [0.1, 0.5]}]\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf = GridSearchCV(clf, tuned_parameters)\n",
    "clf.fit(data, new_targets)\n",
    "\n",
    "print(\"Scores for parameter grid search:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c\n",
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, data, new_targets, cv=5, scoring='roc_auc')\n",
    "print('Logistic Regression ROC AUC scores', scores)\n",
    "print('Logistic Regression ROC AUC Mean score', np.mean(scores))\n",
    "print()\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, data, new_targets, cv=5, scoring='roc_auc')\n",
    "print('Boosting Classifier ROC AUC scores', scores)\n",
    "print('Boosting Classifier ROC AUC Mean score', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2d) Briefly discuss the performance and summarize your findings. Are they good classifiers? Compare the result with a trivial classifier. Compare the results when using accuracy and ROC_AUC.**\n",
    "\n",
    "The performance of the logistic regression and gradient boosting clasifiers was pretty good. The mean accuracy of the models on 5-fold cross validation is as follows:\n",
    "\n",
    "    Logistic Regression Mean Accuracy = 0.7909890954886174\n",
    "    Boosting Classifier Mean Accuracy = 0.786484278963419\n",
    "\n",
    "The accuracies were roughly the same with the logistic regression having a slightly better mean accuracy.\n",
    "\n",
    "The results of ROC_AUC were:\n",
    "\n",
    "    Logistic Regression ROC AUC Mean score 0.8701644975389575\n",
    "    Boosting Classifier ROC AUC Mean score 0.8898095631008707\n",
    "    \n",
    "ROC_AUC measures the ability between [0,1] of a classifier to discriminate between classes of data. Values closer to 1 mean the model is good at discriminating classes. Given the results above, we can say that our model can predict the class of data relatively well. Assuming data is evenly distributed among 2 classes, an untrained trivial classifier would achive ~0.5 accuracy and ROC AUC.\n",
    "\n",
    "The two classifiers performed similarly although the boosting classifier has a slightly greater ROC AUC mean score. The ROC_AUC values are also higher than the accuracy scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
