{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "#sentiment packages\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load business_df dataframe with ALL additional columns\n",
    "# run instead of cells below\n",
    "business_df = pd.read_json('business_df.json', lines=False)\n",
    "\n",
    "# for saving business_df to json file\n",
    "# business_df.to_json(r'business_df.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load business data\n",
    "business_df = pd.read_json('business.json', lines=True)\n",
    "\n",
    "#load tip data\n",
    "tip_df = pd.read_json('tip.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Chain Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary where key=business_name, value=count of that business\n",
    "business_names = {}\n",
    "for index, tip in business_df.iterrows():\n",
    "    business_name = tip['name']\n",
    "    if business_name in business_names:\n",
    "        business_names[business_name] += 1\n",
    "    else:\n",
    "        business_names[business_name] = 1\n",
    "\n",
    "# Add a Boolean column 'chain' to business_df\n",
    "# True if there are more than one business by the same name\n",
    "business_df['chain'] = False\n",
    "for index, business in business_df.iterrows():\n",
    "    business_name = business['name']\n",
    "    if business_names[business_name] > 1:\n",
    "        business_df.at[index, 'chain'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Tip_Count Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of tips matched to business IDs\n",
    "bzn_tips = {}\n",
    "for index, tip in tip_df.iterrows():\n",
    "    business_id = tip['business_id']\n",
    "    if business_id in bzn_tips:\n",
    "        bzn_tips[business_id] += 1\n",
    "    else:\n",
    "        bzn_tips[business_id] = 1\n",
    "\n",
    "# Add a 'tip_count' column to businesses_df dataframe\n",
    "business_df['tip_count'] = 0\n",
    "\n",
    "for index, business in business_df.iterrows():\n",
    "    business_id = business['business_id']\n",
    "    if business_id in bzn_tips:\n",
    "        business_df.at[index, 'tip_count'] = bzn_tips[business_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Tips.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Sentiment Analysis with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data=[]\n",
    "for l in open(\"tip.json\").readlines():\n",
    "    data.append(json.loads(l))\n",
    "tips_sentiment_df = pd.DataFrame.from_records(data[0:1000000])[['business_id', 'text','date']]\n",
    "\n",
    "tips_sentiment_df['sentiment'] = df[['text']].applymap(lambda x: TextBlob(x).sentiment.polarity)\n",
    "tips_sentiment_df.to_json(r'tips_with_sentiment.json',orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add mean_tip_sentiment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate mean sentiments by 'business_id'\n",
    "mean_tips_sentiment = tips_sentiment_df.groupby('business_id').mean()[['sentiment']]\n",
    "\n",
    "# Join/Append 'sentiment' column to business_df\n",
    "business_df = business_df.join(mean_tips_sentiment, on='business_id')\n",
    "\n",
    "# Fill NaNs with mean_sentiment\n",
    "mean_sentiment = business_df['sentiment'].mean()\n",
    "business_df = business_df.fillna(value=mean_sentiment)\n",
    "business_df = business_df.rename(columns={\"sentiment\": \"mean_tip_sentiment\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Neighbor Columns to Illinois data\n",
    "- Begin using illinois_business df instead of business_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-363fffdd834e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiz1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiz1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiz2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiz2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mil_neighbors_far\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbiz2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-363fffdd834e>\u001b[0m in \u001b[0;36mget_distance\u001b[0;34m(lat1, lon1, lat2, lon2)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdlat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlat2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlat1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlat\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlon\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0matan2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_distance(lat1, lon1, lat2, lon2):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)\n",
    "    lat2 = radians(lat2)\n",
    "    lon2 = radians(lon2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "\n",
    "illinois_business = business_df[business_df['state'] == 'ON']\n",
    "\n",
    "bus_loc = [[] for i in range(illinois_business.shape[0])]\n",
    "count = 0\n",
    "for index, row in illinois_business.iterrows():\n",
    "    bus_loc[count].append(row['business_id'])\n",
    "    bus_loc[count].append(row['latitude'])\n",
    "    bus_loc[count].append(row['longitude'])\n",
    "    count += 1\n",
    "    \n",
    "il_neighbors_close = [[] for i in range(len(bus_loc))]\n",
    "il_neighbors_far = [[] for i in range(len(bus_loc))]\n",
    "\n",
    "for i, biz1 in enumerate(bus_loc):\n",
    "    if i % 1000 == 0:\n",
    "                print(i)\n",
    "    for j, biz2 in enumerate(bus_loc):\n",
    "        if i == j:\n",
    "            continue\n",
    "        distance = get_distance(biz1[1], biz1[2], biz2[1], biz2[2])\n",
    "        if distance < 0.3:\n",
    "            il_neighbors_far[i].append([biz2[0], distance])\n",
    "        if distance < 0.1:\n",
    "            il_neighbors_close[i].append([biz2[0], distance])\n",
    "            \n",
    "\n",
    "illinois_business['.1_km'] = il_neighbors_close\n",
    "illinois_business['.3_km'] = il_neighbors_far\n",
    "\n",
    "# number_neighbors_close = [0 for i in range(len(il_neighbors_close))]\n",
    "# number_neighbors_far = [0 for i in range(len(il_neighbors_far))]\n",
    "\n",
    "\n",
    "# for i, bzn in enumerate(il_neighbors_close):\n",
    "#     number_neighbors_close[i] = len(bzn)\n",
    "    \n",
    "# for i, bzn in enumerate(il_neighbors_far):\n",
    "#     number_neighbors_far[i] = len(bzn)\n",
    "\n",
    "illinois_business['.1_count'] = illinois_business['.1_km'].apply(lambda x: len(x))\n",
    "illinois_business['.3_count'] = illinois_business['.3_km'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Logistic Regression of Illinois Businesses with neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1932 entries, 289 to 192521\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   stars               1932 non-null   float64\n",
      " 1   review_count        1932 non-null   int64  \n",
      " 2   chain               1932 non-null   bool   \n",
      " 3   tip_count           1932 non-null   int64  \n",
      " 4   .1_count            1932 non-null   int64  \n",
      " 5   .3_count            1932 non-null   int64  \n",
      " 6   mean_tip_sentiment  1932 non-null   float64\n",
      " 7   mean_tip_sentiment  1932 non-null   float64\n",
      "dtypes: bool(1), float64(3), int64(4)\n",
      "memory usage: 122.6 KB\n"
     ]
    }
   ],
   "source": [
    "il_LogReg_data = illinois_business[['stars', 'review_count', 'chain', 'tip_count', '.1_count', '.3_count', 'mean_tip_sentiment']]\n",
    "il_LogReg_targets = illinois_business['is_open']\n",
    "il_LogReg_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/david/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Scores [0.79328165 0.79844961 0.80569948 0.79533679 0.79274611]\n",
      "Logistic Regression Mean Score 0.797102729913912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, il_LogReg_data, il_LogReg_targets, cv=5)\n",
    "print('Logistic Regression Scores', scores)\n",
    "print('Logistic Regression Mean Score', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier of Illinois Businesses with neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illinois Businesses Boosting Classifier Scores [0.80620155 0.79328165 0.77720207 0.78756477 0.79015544]\n",
      "Illinois Businesses Boosting Classifier Mean Score 0.7908810967854227\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, il_LogReg_data, il_LogReg_targets, cv=5)\n",
    "print('Illinois Businesses Boosting Classifier Scores', scores)\n",
    "print('Illinois Businesses Boosting Classifier Mean Score', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier Parameter Grid Search of Illinois Businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for parameter grid search:\n",
      "\n",
      "0.800 (+/-0.002) for {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 50}\n",
      "0.800 (+/-0.002) for {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 100}\n",
      "0.800 (+/-0.002) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.800 (+/-0.002) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.800 (+/-0.002) for {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 50}\n",
      "0.801 (+/-0.005) for {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 100}\n",
      "0.798 (+/-0.008) for {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.798 (+/-0.012) for {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'max_depth': [2, 3],\n",
    "                     'n_estimators': [50, 100],\n",
    "                     'learning_rate': [0.01, 0.05]}]\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf = GridSearchCV(clf, tuned_parameters)\n",
    "clf.fit(il_LogReg_data, il_LogReg_targets)\n",
    "\n",
    "print(\"Scores for parameter grid search:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression of National Businesses, No Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_data = business_df[['stars', 'review_count', 'chain', 'tip_count', 'mean_tip_sentiment']]\n",
    "national_targets = business_df['is_open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Scores, National [0.82241317 0.82256892 0.82267276 0.822517   0.82266816]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, national_data, national_targets, cv=5)\n",
    "print('Logistic Regression Scores, National', scores)\n",
    "print('Logistic Regression Scores, National Mean Score', np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier of National Businesses, No Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National Business Boosting Classifier Scores [0.8239188  0.82446394 0.82384092 0.82397072 0.82381039]\n",
      "National Business Boosting Classifier Scores Mean Score 0.8240009543138422\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, national_data, national_targets, cv=5)\n",
    "print('National Business Boosting Classifier Scores', scores)\n",
    "print('National Business Boosting Classifier Scores Mean Score', np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC AUC scores for National Businesses, No Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National Neighbor Data Logistic Regression ROC AUC scores [0.59516881 0.60300801 0.58697643 0.59987457 0.59640021]\n",
      "National Neighbor Data Logistic Regression ROC AUC Mean score 0.5962856066310698\n",
      "\n",
      "National Neighbor Data Boosting Classifier ROC AUC scores [0.65414502 0.66674045 0.65784862 0.66802718 0.65924878]\n",
      "National Neighbor Data Boosting Classifier ROC AUC Mean score 0.661202010866172\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, national_data, national_targets, cv=5, scoring='roc_auc')\n",
    "print('National Neighbor Data Logistic Regression ROC AUC scores', scores)\n",
    "print('National Neighbor Data Logistic Regression ROC AUC Mean score', np.mean(scores))\n",
    "print()\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, national_data, national_targets, cv=5, scoring='roc_auc')\n",
    "print('National Neighbor Data Boosting Classifier ROC AUC scores', scores)\n",
    "print('National Neighbor Data Boosting Classifier ROC AUC Mean score', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create neighbor data for national set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_dict = {}\n",
    "for index, row in business_df.iterrows():\n",
    "    state = row['state']\n",
    "    if row['state'] in state_dict:\n",
    "        state_dict[state] += 1\n",
    "    else:\n",
    "        state_dict[state] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business count per state {'AZ': 56686, 'ON': 33412, 'NC': 14720, 'AB': 8012, 'NV': 36312, 'OH': 14697, 'PA': 11216, 'QC': 9219, 'WI': 5154, 'IL': 1932, 'NY': 22, 'SC': 1162, 'TX': 6, 'UT': 1, 'NM': 1, 'FL': 4, 'CA': 19, 'VA': 2, 'BAS': 1, 'NE': 2, 'AK': 2, 'XGM': 4, 'WA': 3, 'XWY': 2, 'CON': 1, 'BC': 1, 'GA': 2, 'VT': 2, 'CT': 3, 'AL': 3, 'DUR': 1, 'TN': 1, 'NJ': 1, 'AR': 1, 'XGL': 1, 'DOW': 1}\n"
     ]
    }
   ],
   "source": [
    "print('business count per state', state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_states = [\"IL\", 'PA', 'AZ', 'ON', 'NC', 'AB', 'NV', 'OH', \"QC\", \"WI\", \"SC\"]\n",
    "large_state_df = business_df[business_df.state.isin(large_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_distance_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IL 0\n",
      "IL 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/david/.local/lib/python3.6/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PA 0\n",
      "PA 1000\n",
      "PA 2000\n",
      "PA 3000\n",
      "PA 4000\n",
      "PA 5000\n",
      "PA 6000\n",
      "PA 7000\n",
      "PA 8000\n",
      "PA 9000\n",
      "PA 10000\n",
      "PA 11000\n",
      "NC 0\n",
      "NC 1000\n",
      "NC 2000\n",
      "NC 3000\n",
      "NC 4000\n",
      "NC 5000\n",
      "NC 6000\n",
      "NC 7000\n",
      "NC 8000\n",
      "NC 9000\n",
      "NC 10000\n",
      "NC 11000\n",
      "NC 12000\n",
      "NC 13000\n",
      "NC 14000\n",
      "AB 0\n",
      "AB 1000\n",
      "AB 2000\n",
      "AB 3000\n",
      "AB 4000\n",
      "AB 5000\n",
      "AB 6000\n",
      "AB 7000\n",
      "AB 8000\n",
      "OH 0\n",
      "OH 1000\n",
      "OH 2000\n",
      "OH 3000\n",
      "OH 4000\n",
      "OH 5000\n",
      "OH 6000\n",
      "OH 7000\n",
      "OH 8000\n",
      "OH 9000\n",
      "OH 10000\n",
      "OH 11000\n",
      "OH 12000\n",
      "OH 13000\n",
      "OH 14000\n",
      "QC 0\n",
      "QC 1000\n",
      "QC 2000\n",
      "QC 3000\n",
      "QC 4000\n",
      "QC 5000\n",
      "QC 6000\n",
      "QC 7000\n",
      "QC 8000\n",
      "QC 9000\n",
      "WI 0\n",
      "WI 1000\n",
      "WI 2000\n",
      "WI 3000\n",
      "WI 4000\n",
      "WI 5000\n",
      "SC 0\n",
      "SC 1000\n"
     ]
    }
   ],
   "source": [
    "for state in large_states:\n",
    "#for i in [1]:\n",
    "    current_state_df = large_state_df[large_state_df.state == state]\n",
    "    if current_state_df.shape[0] < 15000:\n",
    "        bus_loc = [[] for i in range(current_state_df.shape[0])]\n",
    "        count = 0\n",
    "        for index, row in current_state_df.iterrows():\n",
    "            bus_loc[count].append(row['business_id'])\n",
    "            bus_loc[count].append(row['latitude'])\n",
    "            bus_loc[count].append(row['longitude'])\n",
    "            count += 1\n",
    "        \n",
    "        #initialize empty neighbor dict\n",
    "        current_neighbors_close = [[] for i in range(len(bus_loc))]\n",
    "        current_neighbors_far = [[] for i in range(len(bus_loc))]\n",
    "    \n",
    "        for i, biz1 in enumerate(bus_loc):\n",
    "            if i % 1000 == 0:\n",
    "                print(state, i)\n",
    "                \n",
    "            for j, biz2 in enumerate(bus_loc):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                distance = get_distance(biz1[1], biz1[2], biz2[1], biz2[2])\n",
    "                if distance < 0.3:\n",
    "                    current_neighbors_far[i].append([biz2[0], distance])\n",
    "                if distance < 0.1:\n",
    "                    current_neighbors_close[i].append([biz2[0], distance])\n",
    "                    \n",
    "        current_state_df['.1_km'] = current_neighbors_close\n",
    "        current_state_df['.3_km'] = current_neighbors_far\n",
    "        \n",
    "        \n",
    "        completed_distance_df = completed_distance_df.append(current_state_df, ignore_index = True)\n",
    "        current_state_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_distance_df['.1_count'] = completed_distance_df['.1_km'].apply(lambda x: len(x))\n",
    "completed_distance_df['.3_count'] = completed_distance_df['.3_km'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression of National Businesses, With Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_neighbor_data = completed_distance_df[['stars', 'review_count', 'chain', 'tip_count', 'mean_tip_sentiment', '.1_count', '.3_count']]\n",
    "national_neighbor_targets = completed_distance_df['is_open']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Scores, National with neighbors [0.83748015 0.83354761 0.83792165 0.83845107 0.83769475]\n",
      "Logistic Regression Scores, National with neighbors Mean Score 0.837019043597721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, national_neighbor_data, national_neighbor_targets, cv=5)\n",
    "print('Logistic Regression Scores, National with neighbors', scores)\n",
    "print('Logistic Regression Scores, National with neighbors Mean Score', np.mean(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression of National Businesses, With Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National Business Boosting Classifier Scores [0.83846328 0.84005143 0.83981243 0.8399637  0.83761912]\n",
      "National Business Boosting Classifier Scores Mean Score 0.8391819919118255\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, national_neighbor_data, national_neighbor_targets, cv=5)\n",
    "print('National Business Boosting Classifier Scores', scores)\n",
    "print('National Business Boosting Classifier Scores Mean Score', np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier Parameter Grid Search, national data with neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for parameter grid search:\n",
      "\n",
      "0.837 (+/-0.000) for {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 50}\n",
      "0.837 (+/-0.000) for {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 100}\n",
      "0.837 (+/-0.000) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.837 (+/-0.000) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.837 (+/-0.000) for {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 50}\n",
      "0.837 (+/-0.000) for {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 100}\n",
      "0.837 (+/-0.000) for {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.837 (+/-0.000) for {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'max_depth': [2, 3],\n",
    "                     'n_estimators': [50, 100],\n",
    "                     'learning_rate': [0.01, 0.05]}]\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf = GridSearchCV(clf, tuned_parameters)\n",
    "clf.fit(national_neighbor_data, national_neighbor_targets)\n",
    "\n",
    "print(\"Scores for parameter grid search:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC AUC scores for National businesses, with neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National Neighbor Data Logistic Regression ROC AUC scores [0.64188029 0.65383444 0.63374562 0.65935841 0.64030924]\n",
      "National Neighbor Data Logistic Regression ROC AUC Mean score 0.6458255996948443\n",
      "\n",
      "National Neighbor Data Boosting Classifier ROC AUC scores [0.6790938  0.69927051 0.67379396 0.71394055 0.67239222]\n",
      "National Neighbor Data Boosting Classifier ROC AUC Mean score 0.6876982082225859\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, national_neighbor_data, national_neighbor_targets, cv=5, scoring='roc_auc')\n",
    "print('National Neighbor Data Logistic Regression ROC AUC scores', scores)\n",
    "print('National Neighbor Data Logistic Regression ROC AUC Mean score', np.mean(scores))\n",
    "print()\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, national_neighbor_data, national_neighbor_targets, cv=5, scoring='roc_auc')\n",
    "print('National Neighbor Data Boosting Classifier ROC AUC scores', scores)\n",
    "print('National Neighbor Data Boosting Classifier ROC AUC Mean score', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'large_state_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1ac4228bd1c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlarge_state_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'large_state_df' is not defined"
     ]
    }
   ],
   "source": [
    "large_state_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
