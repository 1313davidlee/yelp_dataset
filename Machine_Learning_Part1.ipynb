{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "cal = datasets.fetch_california_housing()\n",
    "data = cal['data']\n",
    "targets = cal['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.30140000e+00,  2.10000000e+01,  6.23813708e+00,  9.71880492e-01,\n",
       "        2.40100000e+03,  2.10984183e+00,  3.78600000e+01, -1.22220000e+02])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R^2 Scores [0.54866323 0.46820691 0.55078434 0.53698703 0.66051406]\n",
      "Linear Regression Mean R^2 Score 0.5530311140279233\n",
      "\n",
      "Boosting R^2 Scores [0.60256286 0.69877396 0.7180343  0.65023363 0.67979733]\n",
      "Boosting Scores Mean R^2 Score 0.6698804157532645\n"
     ]
    }
   ],
   "source": [
    "# 1a\n",
    "clf = LinearRegression()\n",
    "scores = cross_val_score(clf, data, targets, cv=5)\n",
    "print('Linear Regression R^2 Scores', scores)\n",
    "print('Linear Regression Mean R^2 Score', np.mean(scores))\n",
    "print()\n",
    "\n",
    "clf = ensemble.GradientBoostingRegressor()\n",
    "scores = cross_val_score(clf, data, targets, cv=5)\n",
    "print('Boosting R^2 Scores', scores)\n",
    "print('Boosting Scores Mean R^2 Score', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for parameter grid search:\n",
      "\n",
      "0.280 (+/-0.105) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.435 (+/-0.121) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.374 (+/-0.053) for {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50}\n",
      "0.542 (+/-0.077) for {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.633 (+/-0.094) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.670 (+/-0.081) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.652 (+/-0.139) for {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50}\n",
      "0.659 (+/-0.129) for {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# 1b\n",
    "tuned_parameters = [{'max_depth': [3, 10],\n",
    "                     'n_estimators': [50, 100],\n",
    "                     'learning_rate': [0.01, 0.1]}]\n",
    "clf = ensemble.GradientBoostingRegressor()\n",
    "clf = GridSearchCV(clf, tuned_parameters)\n",
    "clf.fit(data, targets)\n",
    "\n",
    "print(\"Scores for parameter grid search:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c) Briefly discuss the performance and summarize your findings.**\n",
    "\n",
    "When running linear regression and gradient boosting using 5-fold cross validation, we got the following R^2 Score results:\n",
    "\n",
    "    Linear Regression Mean Score = 0.5530311140279233\n",
    "    Boosting Scores Mean Score = 0.6698681752149087\n",
    "\n",
    "Overall the scores are not great. R^2 measures the goodness-of-fit of the model on the data. R^2 closer to 1 is better. The boosting score is significantly greater than the linear regressor which makes sense.\n",
    "\n",
    "\n",
    "For 1b) we tested all of the following possible permutations:\n",
    "\n",
    "    'max_depth': [3, 10],\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "    \n",
    "Our parameter grid search yielded interesting results. None of the parameter combinations were convincingly better than the default parameters. In fact, increasing the max_depth and decreasing the learning rate were very detrimental to the R^2 score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_targets = np.array([x>2 for x in targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/David/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/David/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/David/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/David/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/David/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Scores [0.80988133 0.79796512 0.77616279 0.74612403 0.82481221]\n",
      "Logistic Regression Mean Score 0.7909890954886174\n",
      "\n",
      "Boosting Classifier Scores [0.79099055 0.75436047 0.80741279 0.75314922 0.82650836]\n",
      "Boosting Classifier Mean Score 0.786484278963419\n"
     ]
    }
   ],
   "source": [
    "# 2a\n",
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, data, new_targets, cv=5)\n",
    "print('Logistic Regression Scores', scores)\n",
    "print('Logistic Regression Mean Score', np.mean(scores))\n",
    "print()\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, data, new_targets, cv=5)\n",
    "print('Boosting Classifier Scores', scores)\n",
    "print('Boosting Classifier Mean Score', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for parameter grid search:\n",
      "\n",
      "0.788 (+/-0.059) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.774 (+/-0.095) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "0.765 (+/-0.100) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "0.752 (+/-0.125) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "0.751 (+/-0.130) for {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.748 (+/-0.139) for {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 200}\n",
      "0.741 (+/-0.125) for {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 100}\n",
      "0.742 (+/-0.136) for {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# 2b\n",
    "tuned_parameters = [{'max_depth': [3, 5],\n",
    "                     'n_estimators': [100, 200],\n",
    "                     'learning_rate': [0.1, 0.5]}]\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf = GridSearchCV(clf, tuned_parameters)\n",
    "clf.fit(data, new_targets)\n",
    "\n",
    "print(\"Scores for parameter grid search:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/david/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/david/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/david/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/david/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression ROC AUC scores [0.87144465 0.88084073 0.87614029 0.81245699 0.89996528]\n",
      "Boosting Classifier ROC AUC scores [0.8848087  0.84739915 0.90709042 0.9047687  0.91558129]\n"
     ]
    }
   ],
   "source": [
    "# 2c\n",
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, data, new_targets, cv=5, scoring='roc_auc')\n",
    "print('Logistic Regression ROC AUC scores', scores)\n",
    "\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, data, new_targets, cv=5, scoring='roc_auc')\n",
    "print('Boosting Classifier ROC AUC scores', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
